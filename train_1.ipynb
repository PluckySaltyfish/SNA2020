{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from math import cos, sin, atan2, sqrt, pi, radians, degrees, asin\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = read_data('data1/A.csv')\n",
    "B = read_data('data1/B.csv')\n",
    "C = read_data('data1/C.csv')\n",
    "D = read_data('data1/D.csv')\n",
    "E = read_data('data1/E.csv')\n",
    "n_features = A.shape[1] - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "n_step = 1\n",
    "\n",
    "n_ob = n_step * n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(x):\n",
    "    x = x[:4] + ' ' + x[4:6] + ' '+x[6:]\n",
    "    return datetime.strptime(x, '%Y %m %d')\n",
    "def read_data(file):\n",
    "    return pd.read_csv(file, parse_dates=['date'], date_parser=parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def process(cdf):\n",
    "    v = []\n",
    "    for i in range(cdf.region.max()+1):\n",
    "        df = cdf[cdf.region == i].copy()\n",
    "        df = df.set_index(\"date\")\n",
    "        df.drop([\"city\", \"region\"], axis=1, inplace=True)\n",
    "        values = df.values\n",
    "        values = values.astype('float32')\n",
    "        # scaled = scaler.fit_transform(values)\n",
    "        reframed = series_to_supervised(values, n_step, 1)\n",
    "        # reframed.drop(reframed.columns[range(53, 104)], axis=1, inplace=True)\n",
    "        v.append(reframed.values)\n",
    "        a = v[0]\n",
    "        for i in range(1, len(v)):\n",
    "            a = np.concatenate((a, v[i]), axis=0)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A1 = read_data('data/A1.csv')\n",
    "a = process(A)\n",
    "b = process(B)\n",
    "c = process(C)\n",
    "d = process(D)\n",
    "e = process(E)\n",
    "data = np.concatenate((a,b,c,d,e),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[:, :n_ob], data[:, n_ob:], test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], n_step, n_features))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], n_step, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13798, 1, 4) (13798, 4) (3450, 1, 4) (3450, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13798 samples, validate on 3450 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.7022 - val_loss: 0.4078\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.3575 - val_loss: 0.3125\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.2930 - val_loss: 0.2684\n",
      "Epoch 4/10\n",
      " - 6s - loss: 0.2552 - val_loss: 0.2385\n",
      "Epoch 5/10\n",
      " - 6s - loss: 0.2302 - val_loss: 0.2187\n",
      "Epoch 6/10\n",
      " - 6s - loss: 0.2116 - val_loss: 0.2007\n",
      "Epoch 7/10\n",
      " - 6s - loss: 0.1961 - val_loss: 0.1843\n",
      "Epoch 8/10\n",
      " - 6s - loss: 0.1855 - val_loss: 0.1794\n",
      "Epoch 9/10\n",
      " - 6s - loss: 0.1760 - val_loss: 0.1716\n",
      "Epoch 10/10\n",
      " - 6s - loss: 0.1690 - val_loss: 0.1649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x150036410>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(X_test.shape[1], X_test.shape[2])))\n",
    "# model.add(LSTM(units=52))\n",
    "model.add(Dense(n_features))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='msle', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_last_day(cdf):\n",
    "    v = []\n",
    "    for i in range(cdf.region.max()+1):\n",
    "        df = cdf[cdf.region == i].copy()\n",
    "        df = df.set_index(\"date\")\n",
    "        df.drop([\"city\", \"region\"], axis=1, inplace=True)\n",
    "        values = df.values\n",
    "        values = values.astype('float32')\n",
    "        # scaled = scaler.fit_transform(values)\n",
    "        reframed = series_to_supervised(values, n_step, 1)\n",
    "        v.append(np.array([reframed.values[-1]])[:,n_ob:])\n",
    "    return v\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_lastday = process_last_day(A)\n",
    "b_lastday = process_last_day(B)\n",
    "c_lastday = process_last_day(C)\n",
    "d_lastday = process_last_day(D)\n",
    "e_lastday = process_last_day(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(day_before):\n",
    "    day_before = np.reshape(day_before, (day_before.shape[0], n_step, n_features))\n",
    "    day_after = model.predict(day_before)\n",
    "    return day_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_future_prediction(lastday):\n",
    "    res_city_lst = []\n",
    "    for region_begin in lastday:\n",
    "        res_date_lst = [predict(region_begin)]\n",
    "        for i in range(1, 30):\n",
    "            res_date_lst.append(predict(res_date_lst[-1]))\n",
    "        res_city_lst.append(res_date_lst)\n",
    "    return res_city_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_prediction = generate_future_prediction(a_lastday)\n",
    "b_prediction = generate_future_prediction(b_lastday)\n",
    "c_prediction = generate_future_prediction(c_lastday)\n",
    "d_prediction = generate_future_prediction(d_lastday)\n",
    "e_prediction = generate_future_prediction(e_lastday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.64315  ,  0.2013173,  0.4866501,  8.247681 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_res_infection_lst(cities_prediction):\n",
    "    res_infection = []\n",
    "    res_region = []\n",
    "    for city_prediction in cities_prediction:\n",
    "        region_id = 0\n",
    "        for region in city_prediction:\n",
    "            for date in region:\n",
    "                res_infection.append(int(round(date[0][0])))\n",
    "                res_region.append(region_id)\n",
    "            region_id = region_id + 1\n",
    "    return res_infection, res_region\n",
    "def check_minus(infection):\n",
    "    for i in range(len(infection)):\n",
    "        if infection[i] < 0:\n",
    "            if infection[i - 1] < 6:\n",
    "                infection[i] = 0\n",
    "            else:\n",
    "                infection[i] = int(infection[i - 1])\n",
    "    return infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "infection, region = generate_res_infection_lst([a_prediction,b_prediction,c_prediction,d_prediction,e_prediction])\n",
    "infection = check_minus(infection)\n",
    "submission = pd.read_csv('submission.csv', header=None, names=['city','region','date','infection'])\n",
    "submission['infection'] = infection\n",
    "submission['region'] = region\n",
    "submission.to_csv('test_submission_4.csv',index=False,header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
